{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea5d4d38",
   "metadata": {},
   "source": [
    "### Scrapes the data using selenium and stores it in json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"updated_instagram.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Path to the Edge WebDriver executable\n",
    "edge_driver_path = \"C:\\\\Users\\\\Harsh Dipak Marke\\\\Data Science Project\\\\msedgedriver.exe\"\n",
    "\n",
    "# Initialize Microsoft Edge WebDriver with the specified path\n",
    "service = Service(edge_driver_path)\n",
    "driver = webdriver.Edge(service=service)\n",
    "\n",
    "# URL of the Instagram login page\n",
    "login_url = 'https://www.instagram.com/accounts/login/'\n",
    "\n",
    "# Load the Instagram login page\n",
    "driver.get(login_url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the username and password input fields and enter your credentials\n",
    "username_input = driver.find_element(By.NAME, \"username\")\n",
    "password_input = driver.find_element(By.NAME, \"password\")\n",
    "\n",
    "# Replace 'your_username' and 'your_password' with your actual Instagram credentials\n",
    "username_input.send_keys(\"ds_harsh_1\")\n",
    "password_input.send_keys(\"Harsh@123\")\n",
    "\n",
    "# Submit the login form\n",
    "password_input.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the login process to complete\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "for index, row in df.iloc[160:].iterrows():\n",
    "    url = row['Instagram_url']\n",
    "    username = row['Instagram name']\n",
    "    \n",
    "    # URL of the Instagram profile you want to scrape\n",
    "    profile_url = url\n",
    "\n",
    "    # Load the Instagram profile page\n",
    "    driver.get(profile_url)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        followers_element = driver.find_element(By.XPATH, f'//a[contains(@href, \"/{username}/followers/\")]/span')\n",
    "        followers_count = followers_element.text\n",
    "    except NoSuchElementException:\n",
    "        followers_count = \"0\"\n",
    "\n",
    "    try:\n",
    "        following_element = driver.find_element(By.XPATH, f'//a[contains(@href, \"/{username}/following/\")]/span')\n",
    "        following_count = following_element.text\n",
    "    except NoSuchElementException:\n",
    "        following_count = \"0\"\n",
    "\n",
    "    try:\n",
    "        posts_element = driver.find_element(By.XPATH, '//span[@class=\"html-span xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x1hl2dhg x16tdsg8 x1vvkbs\"]')\n",
    "        posts_count = posts_element.text\n",
    "    except NoSuchElementException:\n",
    "        posts_count = \"0\"\n",
    "\n",
    "    # Example: Scraping the URL of the profile picture\n",
    "    profile_picture_elements = driver.find_elements(By.XPATH, '//img[contains(@alt, \"\\'s profile picture\")]')\n",
    "    if profile_picture_elements:\n",
    "        profile_picture_url = profile_picture_elements[0].get_attribute(\"src\")\n",
    "    else:\n",
    "        profile_picture_url = \"#\"\n",
    "\n",
    "    # Find all the div tags with the specified class name\n",
    "    post_divs = driver.find_elements(By.CLASS_NAME, '_aabd')\n",
    "\n",
    "    # Initialize an empty list to store information about each post\n",
    "    posts_info = []\n",
    "\n",
    "    # Iterate through each div tag to extract post information\n",
    "    \n",
    "    for post_div in post_divs:\n",
    "        post_info = {}\n",
    "        # Extract post URL\n",
    "        post_a_tag = post_div.find_element(By.TAG_NAME, 'a')\n",
    "        post_info['url'] = post_a_tag.get_attribute('href')\n",
    "\n",
    "        # Extract post image URL\n",
    "        post_img_tag = post_div.find_element(By.TAG_NAME, 'img')\n",
    "        post_info['urlImage'] = post_img_tag.get_attribute('src')\n",
    "\n",
    "        # Extract post description (alt text)\n",
    "        description = post_img_tag.get_attribute('alt')\n",
    "        post_info['description'] = description if description else \"\"\n",
    "\n",
    "        # Extract mentions (strings starting with '@') from the description\n",
    "        mentions = [word for word in description.split() if word.startswith('@')]\n",
    "        post_info['mentions'] = mentions\n",
    "\n",
    "        posts_info.append(post_info)\n",
    "\n",
    "    likes_counts = []\n",
    "\n",
    "    # Iterate through each URL in the array\n",
    "    if len(posts_info) == 0:\n",
    "        driver.quit()\n",
    "        \n",
    "    post_count = 0\n",
    "    zero_likes = 0\n",
    "    for post in posts_info:\n",
    "        # Load the URL\n",
    "        driver.get(post['url'])\n",
    "        time.sleep(5)  \n",
    "        post_count = post_count + 1\n",
    "\n",
    "        try:\n",
    "            # Find the span tag containing the likes count\n",
    "            likes_span = driver.find_element(By.XPATH, '//span[@class=\"html-span xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x1hl2dhg x16tdsg8 x1vvkbs\"]')\n",
    "\n",
    "            # Extract the text from the span tag\n",
    "            likes_count = likes_span.text\n",
    "        except NoSuchElementException:\n",
    "            likes_count = \"0\"  # Set likes count to \"0\" if element is not found\n",
    "            zero_likes = zero_likes + 1\n",
    "\n",
    "        # Append the likes count to the list\n",
    "        likes_counts.append(likes_count)\n",
    "\n",
    "    # Close the WebDriver\n",
    "    if(post_count != 0 and post_count == zero_likes):\n",
    "        driver.quit()\n",
    "\n",
    "    # Append the likes count to the corresponding post\n",
    "    i = 0\n",
    "    for post in posts_info:\n",
    "        post['likes'] = likes_counts[i]\n",
    "        i += 1\n",
    "\n",
    "    user_data = {}\n",
    "    # Define the path to the folder\n",
    "    folder_path = \"JSON-files\"\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    user_data['username'] = username\n",
    "    user_data['profile_url'] = profile_url\n",
    "    user_data['followers'] = followers_count\n",
    "    user_data['following'] = following_count\n",
    "    user_data['number_of_posts'] = posts_count\n",
    "    user_data['posts_info'] = posts_info\n",
    "\n",
    "    json_file_path = os.path.join(folder_path, f\"{username}.json\")\n",
    "\n",
    "    # Write the user data to the JSON file\n",
    "    with open(json_file_path, \"w\") as json_file:\n",
    "        json.dump(user_data, json_file, indent=4)\n",
    "\n",
    "    print(f\"JSON file saved successfully at: {json_file_path}\")\n",
    "\n",
    "    \n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
